{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36664bit0dae64bc2c7f4db3a79eae90e3d548d6",
   "display_name": "Python 3.6.6 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "rom sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('diabetes_data.csv')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "obj=StandardScaler()\n",
    "x=df.iloc[:,0:8]\n",
    "x=obj.fit_transform(x)\n",
    "y=df['diabetes'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp=MLPClassifier(hidden_layer_sizes=(8,8,8),activation='relu',solver='sgd',learning_rate='adaptive',verbose=True,max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n       hidden_layer_sizes=(8, 8, 8), learning_rate='adaptive',\n       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n       nesterovs_momentum=True, power_t=0.5, random_state=None,\n       shuffle=True, solver='sgd', tol=0.0001, validation_fraction=0.1,\n       verbose=True, warm_start=False)"
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Iteration 1, loss = 1.24884446\nIteration 2, loss = 0.84247327\nIteration 3, loss = 0.71154685\nIteration 4, loss = 0.68218456\nIteration 5, loss = 0.66255637\nIteration 6, loss = 0.63036014\nIteration 7, loss = 0.62118783\nIteration 8, loss = 0.61637167\nIteration 9, loss = 0.61087324\nIteration 10, loss = 0.60842794\nIteration 11, loss = 0.60801248\nIteration 12, loss = 0.60287468\nIteration 13, loss = 0.60225296\nIteration 14, loss = 0.59984870\nIteration 15, loss = 0.59811507\nIteration 16, loss = 0.59747806\nIteration 17, loss = 0.59729183\nIteration 18, loss = 0.59347209\nIteration 19, loss = 0.59797622\nIteration 20, loss = 0.59058790\nIteration 21, loss = 0.59054256\nIteration 22, loss = 0.59276981\nIteration 23, loss = 0.59404398\nTraining loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000200\nIteration 24, loss = 0.58634054\nIteration 25, loss = 0.58396923\nIteration 26, loss = 0.58413134\nIteration 27, loss = 0.58254055\nIteration 28, loss = 0.58129877\nIteration 29, loss = 0.58273769\nIteration 30, loss = 0.57983626\nIteration 31, loss = 0.58104870\nIteration 32, loss = 0.58020946\nIteration 33, loss = 0.57921341\nIteration 34, loss = 0.57800960\nIteration 35, loss = 0.57939781\nIteration 36, loss = 0.57768490\nIteration 37, loss = 0.57702233\nIteration 38, loss = 0.57801022\nIteration 39, loss = 0.57710355\nIteration 40, loss = 0.57666152\nIteration 41, loss = 0.57605958\nIteration 42, loss = 0.57629935\nIteration 43, loss = 0.57620025\nIteration 44, loss = 0.57557740\nIteration 45, loss = 0.57529397\nIteration 46, loss = 0.57561144\nIteration 47, loss = 0.57495552\nIteration 48, loss = 0.57527299\nIteration 49, loss = 0.57502679\nIteration 50, loss = 0.57448285\nIteration 51, loss = 0.57493609\nIteration 52, loss = 0.57509932\nIteration 53, loss = 0.57616684\nTraining loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000040\nIteration 54, loss = 0.57419936\nIteration 55, loss = 0.57436240\nIteration 56, loss = 0.57444371\nIteration 57, loss = 0.57396910\nIteration 58, loss = 0.57374453\nIteration 59, loss = 0.57351184\nIteration 60, loss = 0.57347242\nIteration 61, loss = 0.57346159\nIteration 62, loss = 0.57340706\nTraining loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000008\nIteration 63, loss = 0.57330712\nIteration 64, loss = 0.57331758\nIteration 65, loss = 0.57326901\nTraining loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000002\nIteration 66, loss = 0.57323227\nIteration 67, loss = 0.57320950\nIteration 68, loss = 0.57321901\nTraining loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000000\nIteration 69, loss = 0.57319677\nIteration 70, loss = 0.57319164\nIteration 71, loss = 0.57319193\nTraining loss did not improve more than tol=0.000100 for two consecutive epochs. Learning rate too small. Stopping.\n"
    },
    {
     "data": {
      "text/plain": "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n       hidden_layer_sizes=(8, 8, 8), learning_rate='adaptive',\n       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n       nesterovs_momentum=True, power_t=0.5, random_state=None,\n       shuffle=True, solver='sgd', tol=0.0001, validation_fraction=0.1,\n       verbose=True, warm_start=False)"
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=mlp.predict(X_test)\n",
    "predict2=mlp.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "score1=mlp.score(X_test,y_test)*100\n",
    "score2=mlp.score(X_train,y_train)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "72.72727272727273\n72.64833574529666\n"
    }
   ],
   "source": [
    "print(score1)\n",
    "print(score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[1.2488444647505357,\n 0.8424732741179708,\n 0.7115468483469655,\n 0.6821845570606693,\n 0.6625563691906352,\n 0.630360135432195,\n 0.6211878253683593,\n 0.616371669001787,\n 0.6108732446592332,\n 0.6084279397777818,\n 0.6080124814416602,\n 0.6028746834129448,\n 0.602252958691346,\n 0.599848696171396,\n 0.5981150696874773,\n 0.5974780613039865,\n 0.59729183252528,\n 0.5934720882989326,\n 0.5979762243211872,\n 0.590587900439118,\n 0.5905425555412176,\n 0.5927698050947293,\n 0.5940439842106455,\n 0.5863405352135972,\n 0.5839692250595719,\n 0.5841313372358299,\n 0.5825405458978677,\n 0.5812987714771752,\n 0.5827376871108844,\n 0.5798362634183749,\n 0.581048699554607,\n 0.5802094611829408,\n 0.5792134056598383,\n 0.5780096017761084,\n 0.5793978092022479,\n 0.5776849019980863,\n 0.5770223300271661,\n 0.5780102157617615,\n 0.5771035519233957,\n 0.5766615191553018,\n 0.5760595763319123,\n 0.5762993528364319,\n 0.5762002453375975,\n 0.5755773989238996,\n 0.5752939715704161,\n 0.5756114410594957,\n 0.5749555150136879,\n 0.5752729882083937,\n 0.5750267869833677,\n 0.5744828465095582,\n 0.5749360866684994,\n 0.5750993168244719,\n 0.5761668449577491,\n 0.574199360250916,\n 0.5743623983391463,\n 0.574443709077926,\n 0.5739691047039213,\n 0.5737445304501488,\n 0.5735118377883487,\n 0.5734724243781424,\n 0.5734615903059009,\n 0.573407061057127,\n 0.5733071225335531,\n 0.5733175775475943,\n 0.5732690084181347,\n 0.5732322701815803,\n 0.5732095046086323,\n 0.573219011483431,\n 0.5731967668654174,\n 0.5731916425066363,\n 0.5731919276365837]"
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.loss_curve_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}