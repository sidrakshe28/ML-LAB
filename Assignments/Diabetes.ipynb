{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('diabetes_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>diastolic</th>\n",
       "      <th>triceps</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>dpf</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  diastolic  triceps  insulin   bmi    dpf  age  \\\n",
       "0            6      148         72       35        0  33.6  0.627   50   \n",
       "1            1       85         66       29        0  26.6  0.351   31   \n",
       "2            8      183         64        0        0  23.3  0.672   32   \n",
       "3            1       89         66       23       94  28.1  0.167   21   \n",
       "4            0      137         40       35      168  43.1  2.288   33   \n",
       "\n",
       "   diabetes  \n",
       "0         1  \n",
       "1         0  \n",
       "2         1  \n",
       "3         0  \n",
       "4         1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()\n",
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=dataset.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    1\n",
       "Name: diabetes, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-cf3860942b4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.63994726,  0.84832379,  0.14964075,  0.90726993, -0.69289057,\n",
       "        0.20401277,  0.46849198,  1.4259954 ])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(hidden_layer_sizes=(128,64,32), activation='relu',solver='adam',verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.73095840\n",
      "Iteration 2, loss = 0.68379257\n",
      "Iteration 3, loss = 0.65421174\n",
      "Iteration 4, loss = 0.63283919\n",
      "Iteration 5, loss = 0.61335423\n",
      "Iteration 6, loss = 0.59358522\n",
      "Iteration 7, loss = 0.57358687\n",
      "Iteration 8, loss = 0.55183676\n",
      "Iteration 9, loss = 0.53100974\n",
      "Iteration 10, loss = 0.51303990\n",
      "Iteration 11, loss = 0.49835862\n",
      "Iteration 12, loss = 0.48636589\n",
      "Iteration 13, loss = 0.47845293\n",
      "Iteration 14, loss = 0.47160601\n",
      "Iteration 15, loss = 0.46565667\n",
      "Iteration 16, loss = 0.46204190\n",
      "Iteration 17, loss = 0.46078102\n",
      "Iteration 18, loss = 0.45868432\n",
      "Iteration 19, loss = 0.45282513\n",
      "Iteration 20, loss = 0.45109015\n",
      "Iteration 21, loss = 0.45259095\n",
      "Iteration 22, loss = 0.45167294\n",
      "Iteration 23, loss = 0.44843951\n",
      "Iteration 24, loss = 0.44569244\n",
      "Iteration 25, loss = 0.44365482\n",
      "Iteration 26, loss = 0.44020201\n",
      "Iteration 27, loss = 0.43727348\n",
      "Iteration 28, loss = 0.43650728\n",
      "Iteration 29, loss = 0.43626845\n",
      "Iteration 30, loss = 0.43744574\n",
      "Iteration 31, loss = 0.43424755\n",
      "Iteration 32, loss = 0.43115048\n",
      "Iteration 33, loss = 0.42952639\n",
      "Iteration 34, loss = 0.42867948\n",
      "Iteration 35, loss = 0.42730545\n",
      "Iteration 36, loss = 0.42576165\n",
      "Iteration 37, loss = 0.42360623\n",
      "Iteration 38, loss = 0.42287953\n",
      "Iteration 39, loss = 0.42131268\n",
      "Iteration 40, loss = 0.42215953\n",
      "Iteration 41, loss = 0.42169118\n",
      "Iteration 42, loss = 0.41894463\n",
      "Iteration 43, loss = 0.41617076\n",
      "Iteration 44, loss = 0.41476203\n",
      "Iteration 45, loss = 0.41358578\n",
      "Iteration 46, loss = 0.41324642\n",
      "Iteration 47, loss = 0.41012673\n",
      "Iteration 48, loss = 0.40768497\n",
      "Iteration 49, loss = 0.40629664\n",
      "Iteration 50, loss = 0.40553911\n",
      "Iteration 51, loss = 0.40684034\n",
      "Iteration 52, loss = 0.40463236\n",
      "Iteration 53, loss = 0.40588723\n",
      "Iteration 54, loss = 0.40480503\n",
      "Iteration 55, loss = 0.40189926\n",
      "Iteration 56, loss = 0.40380221\n",
      "Iteration 57, loss = 0.40141566\n",
      "Iteration 58, loss = 0.39637914\n",
      "Iteration 59, loss = 0.39465812\n",
      "Iteration 60, loss = 0.39618606\n",
      "Iteration 61, loss = 0.39690503\n",
      "Iteration 62, loss = 0.39225311\n",
      "Iteration 63, loss = 0.39154155\n",
      "Iteration 64, loss = 0.38844776\n",
      "Iteration 65, loss = 0.38604261\n",
      "Iteration 66, loss = 0.38560753\n",
      "Iteration 67, loss = 0.38439241\n",
      "Iteration 68, loss = 0.38270521\n",
      "Iteration 69, loss = 0.38019845\n",
      "Iteration 70, loss = 0.37761077\n",
      "Iteration 71, loss = 0.38232973\n",
      "Iteration 72, loss = 0.37823098\n",
      "Iteration 73, loss = 0.37543572\n",
      "Iteration 74, loss = 0.37863868\n",
      "Iteration 75, loss = 0.37333351\n",
      "Iteration 76, loss = 0.37876779\n",
      "Iteration 77, loss = 0.37485664\n",
      "Iteration 78, loss = 0.37172339\n",
      "Iteration 79, loss = 0.37331621\n",
      "Iteration 80, loss = 0.37250984\n",
      "Iteration 81, loss = 0.36754437\n",
      "Iteration 82, loss = 0.36360359\n",
      "Iteration 83, loss = 0.36321084\n",
      "Iteration 84, loss = 0.36646838\n",
      "Iteration 85, loss = 0.36285129\n",
      "Iteration 86, loss = 0.36255930\n",
      "Iteration 87, loss = 0.35936298\n",
      "Iteration 88, loss = 0.35449294\n",
      "Iteration 89, loss = 0.35249377\n",
      "Iteration 90, loss = 0.34962407\n",
      "Iteration 91, loss = 0.35427821\n",
      "Iteration 92, loss = 0.35159869\n",
      "Iteration 93, loss = 0.34640372\n",
      "Iteration 94, loss = 0.34728936\n",
      "Iteration 95, loss = 0.34582545\n",
      "Iteration 96, loss = 0.34006231\n",
      "Iteration 97, loss = 0.33910068\n",
      "Iteration 98, loss = 0.33857385\n",
      "Iteration 99, loss = 0.33843259\n",
      "Iteration 100, loss = 0.33344342\n",
      "Iteration 101, loss = 0.33856838\n",
      "Iteration 102, loss = 0.34075534\n",
      "Iteration 103, loss = 0.33207877\n",
      "Iteration 104, loss = 0.34831237\n",
      "Iteration 105, loss = 0.33421329\n",
      "Iteration 106, loss = 0.34108418\n",
      "Iteration 107, loss = 0.33871756\n",
      "Iteration 108, loss = 0.32320518\n",
      "Iteration 109, loss = 0.32836766\n",
      "Iteration 110, loss = 0.32604457\n",
      "Iteration 111, loss = 0.32051279\n",
      "Iteration 112, loss = 0.31533749\n",
      "Iteration 113, loss = 0.31545827\n",
      "Iteration 114, loss = 0.31912440\n",
      "Iteration 115, loss = 0.31388811\n",
      "Iteration 116, loss = 0.31313180\n",
      "Iteration 117, loss = 0.31621893\n",
      "Iteration 118, loss = 0.30987723\n",
      "Iteration 119, loss = 0.30431766\n",
      "Iteration 120, loss = 0.30728241\n",
      "Iteration 121, loss = 0.30941182\n",
      "Iteration 122, loss = 0.29707590\n",
      "Iteration 123, loss = 0.30011314\n",
      "Iteration 124, loss = 0.30358200\n",
      "Iteration 125, loss = 0.30217375\n",
      "Iteration 126, loss = 0.29695260\n",
      "Iteration 127, loss = 0.29965179\n",
      "Iteration 128, loss = 0.30429373\n",
      "Iteration 129, loss = 0.30135048\n",
      "Iteration 130, loss = 0.29166125\n",
      "Iteration 131, loss = 0.28746248\n",
      "Iteration 132, loss = 0.28071005\n",
      "Iteration 133, loss = 0.28366668\n",
      "Iteration 134, loss = 0.28993497\n",
      "Iteration 135, loss = 0.27677471\n",
      "Iteration 136, loss = 0.28028651\n",
      "Iteration 137, loss = 0.27039332\n",
      "Iteration 138, loss = 0.27295178\n",
      "Iteration 139, loss = 0.26829315\n",
      "Iteration 140, loss = 0.28038591\n",
      "Iteration 141, loss = 0.27481921\n",
      "Iteration 142, loss = 0.26499763\n",
      "Iteration 143, loss = 0.26544587\n",
      "Iteration 144, loss = 0.27072267\n",
      "Iteration 145, loss = 0.26326782\n",
      "Iteration 146, loss = 0.26050082\n",
      "Iteration 147, loss = 0.26404507\n",
      "Iteration 148, loss = 0.25337199\n",
      "Iteration 149, loss = 0.26692058\n",
      "Iteration 150, loss = 0.25354838\n",
      "Iteration 151, loss = 0.25555085\n",
      "Iteration 152, loss = 0.25825475\n",
      "Iteration 153, loss = 0.25888847\n",
      "Iteration 154, loss = 0.25558813\n",
      "Iteration 155, loss = 0.24687953\n",
      "Iteration 156, loss = 0.25932545\n",
      "Iteration 157, loss = 0.24293185\n",
      "Iteration 158, loss = 0.24829284\n",
      "Iteration 159, loss = 0.24680838\n",
      "Iteration 160, loss = 0.26257456\n",
      "Iteration 161, loss = 0.23733002\n",
      "Iteration 162, loss = 0.23744906\n",
      "Iteration 163, loss = 0.23201843\n",
      "Iteration 164, loss = 0.22947601\n",
      "Iteration 165, loss = 0.22524135\n",
      "Iteration 166, loss = 0.22248267\n",
      "Iteration 167, loss = 0.22442863\n",
      "Iteration 168, loss = 0.22490000\n",
      "Iteration 169, loss = 0.22257901\n",
      "Iteration 170, loss = 0.22238954\n",
      "Iteration 171, loss = 0.21809558\n",
      "Iteration 172, loss = 0.21417602\n",
      "Iteration 173, loss = 0.21386573\n",
      "Iteration 174, loss = 0.21012286\n",
      "Iteration 175, loss = 0.20796211\n",
      "Iteration 176, loss = 0.20499378\n",
      "Iteration 177, loss = 0.20746302\n",
      "Iteration 178, loss = 0.21226995\n",
      "Iteration 179, loss = 0.20633491\n",
      "Iteration 180, loss = 0.20124590\n",
      "Iteration 181, loss = 0.20394062\n",
      "Iteration 182, loss = 0.19719903\n",
      "Iteration 183, loss = 0.19143782\n",
      "Iteration 184, loss = 0.19502272\n",
      "Iteration 185, loss = 0.19201203\n",
      "Iteration 186, loss = 0.19488213\n",
      "Iteration 187, loss = 0.19453379\n",
      "Iteration 188, loss = 0.20009333\n",
      "Iteration 189, loss = 0.18975687\n",
      "Iteration 190, loss = 0.18405484\n",
      "Iteration 191, loss = 0.18891280\n",
      "Iteration 192, loss = 0.18099896\n",
      "Iteration 193, loss = 0.18618300\n",
      "Iteration 194, loss = 0.18535757\n",
      "Iteration 195, loss = 0.19028457\n",
      "Iteration 196, loss = 0.18717083\n",
      "Iteration 197, loss = 0.17227727\n",
      "Iteration 198, loss = 0.17778920\n",
      "Iteration 199, loss = 0.19180947\n",
      "Iteration 200, loss = 0.16969357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(128, 64, 32), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
